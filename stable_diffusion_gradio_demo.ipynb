{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "tsvmdwcVfcEX",
        "I1g6lXs7fhzP",
        "B4kKexfW7vkV",
        "LEWVTKV0x2QF",
        "8eNwmhNLpHMW"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stable diffusion using gradio"
      ],
      "metadata": {
        "id": "Ri2jhtHiatUg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "Stable diffusionのtext2imgを利用した画像生成のサンプルコードです。実行環境としては、Google ColabのGPUを想定しています。\n",
        "また、gradioを利用してUIを提供しています。\n",
        "実行にはhugging faceのアカウントを取得し、access tokenを取得する必要があります。取得したaccess tokenは、 `notebook_login` で入力してください。入力のためのUIが出現します。"
      ],
      "metadata": {
        "id": "N9RiRN0Npa4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install packages"
      ],
      "metadata": {
        "id": "tsvmdwcVfcEX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJHh_Bl_alQ1"
      },
      "outputs": [],
      "source": [
        "def _install_packages() -> None:\n",
        "    # Install stable diffusion\n",
        "    !pip install --quiet --no-cache \\\n",
        "        diffusers==0.3.0 \\\n",
        "        ftfy \\\n",
        "        scipy \\\n",
        "        transformers\n",
        "    # Install fugginface hub\n",
        "    !pip install --quiet --no-cache huggingface_hub\n",
        "    # Install ui\n",
        "    !pip install --quiet --no-cache gradio\n",
        "\n",
        "\n",
        "_install_packages()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import packages"
      ],
      "metadata": {
        "id": "I1g6lXs7fhzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from getpass import getpass\n",
        "from pathlib import Path\n",
        "import functools\n",
        "\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "import gradio as gr\n",
        "from huggingface_hub import notebook_login\n",
        "from IPython.display import display\n",
        "from IPython.display import Image as displayImage\n",
        "from PIL.Image import Image"
      ],
      "metadata": {
        "id": "dkTPlO2Wfk5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "gVvR6c1aw7pO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Device"
      ],
      "metadata": {
        "id": "B4kKexfW7vkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select cuda(use gpu) or cpu\n",
        "DEVICE = \"cuda\""
      ],
      "metadata": {
        "id": "dl6uFdjj7vOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### login hugging face"
      ],
      "metadata": {
        "id": "CJMRacKnxzUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "Y0uUAGhdw9hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## prepare pipe"
      ],
      "metadata": {
        "id": "LEWVTKV0x2QF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _create_pipeline(device: str) -> StableDiffusionPipeline:\n",
        "    # Create pipeline using stable diffusion v1.4\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        \"CompVis/stable-diffusion-v1-4\",\n",
        "        revision=\"fp16\",\n",
        "        torch_device=torch.float16,\n",
        "        use_auth_token=True,\n",
        "    )\n",
        "    pipe.to(device)\n",
        "\n",
        "    return pipe\n",
        "\n",
        "\n",
        "PIPE = _create_pipeline(device=DEVICE)"
      ],
      "metadata": {
        "id": "mFTqudwcyBvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UI"
      ],
      "metadata": {
        "id": "s2VrPOWEfgAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### functions"
      ],
      "metadata": {
        "id": "8eNwmhNLpHMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _infer(\n",
        "    pipe: StableDiffusionPipeline,\n",
        "    device: str,  # device info: cuda or cpu.\n",
        "    prompt: str,\n",
        "    num_images: float,  # number of generated images.\n",
        "    height: float,  # image height.\n",
        "    width: float,  # image width.\n",
        "    guidance_scale: float,\n",
        "    num_inference_steps: float,\n",
        "    seed: float,  # random seed for latent space.\n",
        ") -> list[Image]:\n",
        "    # Generate image from prompt string.\n",
        "    num_images = int(num_images)\n",
        "    height = int(height)\n",
        "    width = int(width)\n",
        "    num_inference_steps = int(num_inference_steps)\n",
        "    seed = int(seed)\n",
        "\n",
        "    # initialize latent space.\n",
        "    generator = torch.Generator(device=device).manual_seed(seed)\n",
        "    latents = torch.randn(\n",
        "        (num_images, pipe.unet.in_channels, height // 8, width // 8),\n",
        "        generator=generator,\n",
        "        device=device,\n",
        "    )\n",
        "\n",
        "    # generate images.\n",
        "    images = list()\n",
        "    for latent in latents:\n",
        "        with torch.autocast(device):\n",
        "            image = pipe(\n",
        "                [prompt],\n",
        "                width=width,\n",
        "                height=height,\n",
        "                guidance_scale=guidance_scale,\n",
        "                num_inference_steps=num_inference_steps,\n",
        "                latents=latent.unsqueeze(0),\n",
        "            )[\"sample\"]\n",
        "        images.append(image[0])\n",
        "\n",
        "    return images"
      ],
      "metadata": {
        "id": "BZ99dkOvye2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradio_block(pipe: StableDiffusionPipeline, device: str) -> None:\n",
        "    # UI using gradio.\n",
        "    with gr.Blocks() as demo:\n",
        "        prompt = gr.Textbox(label=\"Enter prompt\", lines=7)\n",
        "        run_button = gr.Button(\"Run\")\n",
        "        with gr.Accordion(\"See details\", open=False):\n",
        "            number_of_images = gr.Number(label=\"Enter number of images\", value=1)\n",
        "            image_height = gr.Slider(\n",
        "                label=\"Enter height of images\",\n",
        "                minimum=64,\n",
        "                maximum=1024,\n",
        "                value=512,\n",
        "                step=8,\n",
        "            )\n",
        "            image_width = gr.Slider(\n",
        "                label=\"Enter width of images\",\n",
        "                minimum=64,\n",
        "                maximum=1024,\n",
        "                value=512,\n",
        "                step=8,\n",
        "            )\n",
        "            number_of_inference_step = gr.Slider(\n",
        "                label=\"Number of inference step\",\n",
        "                minimum=1,\n",
        "                maximum=200,\n",
        "                value=50,\n",
        "                step=1,\n",
        "            )\n",
        "            guidance_scale = gr.Slider(\n",
        "                label=\"Guidance scale\",\n",
        "                minimum=1,\n",
        "                maximum=20,\n",
        "                value=7.5,\n",
        "                step=0.1,\n",
        "            )\n",
        "            seed = gr.Number(label=\"random seed\", value=42)\n",
        "        gallery = gr.Gallery(label=\"Generated images\", show_label=False).style(grid=2)\n",
        "        run_button.click(\n",
        "            functools.partial(_infer, pipe, device),\n",
        "            inputs=[\n",
        "                prompt,\n",
        "                number_of_images,\n",
        "                image_height,\n",
        "                image_width,\n",
        "                guidance_scale,\n",
        "                number_of_inference_step,\n",
        "                seed\n",
        "            ],\n",
        "            outputs=gallery,\n",
        "        )\n",
        "\n",
        "        demo.launch(debug=False, share=True)  # colab利用の場合は、share=True以外は許容されない。\n",
        "\n"
      ],
      "metadata": {
        "id": "csr96Ig8a14D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View"
      ],
      "metadata": {
        "id": "b7fKHQLApKE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gradio_block(pipe=PIPE, device=DEVICE)"
      ],
      "metadata": {
        "id": "eRFJZiTR7Kp9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}