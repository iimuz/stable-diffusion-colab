{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":["UgqwJJVncSmN","qruzggMockGC"],"authorship_tag":"ABX9TyO74DQ9saulhqQwlvaaVrNZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Stable diffusion image to image"],"metadata":{"id":"1A-S3qROb8YZ"}},{"cell_type":"markdown","source":["## Overview\n","\n","Hugging FaceのStable Diffusionを利用した画像から画像を生成するノートブック。公開されている重みをそのまま利用して実行しています。実行するためには、Hugging Faceのアカウントを取得し、APIキーが必要となります。"],"metadata":{"id":"NNySUiTocA_V"}},{"cell_type":"markdown","source":["## Install packages"],"metadata":{"id":"UgqwJJVncSmN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"e8YzhuGVbd5e"},"outputs":[],"source":["def _install_packages() -> None:\n","    # Install packages\n","    !pip install --quiet --no-cache \\\n","        diffusers==0.3.0 \\\n","        ftfy \\\n","        scipy \\\n","        transformers\n","    !pip install -quiet --no-cache huggingface_hub\n","\n","\n","_install_packages()"]},{"cell_type":"markdown","source":["## Import packages"],"metadata":{"id":"qruzggMockGC"}},{"cell_type":"code","source":["from __future__ import annotations\n","\n","from getpass import getpass\n","from pathlib import Path\n","\n","import numpy as np\n","import torch\n","from diffusers import StableDiffusionImg2ImgPipeline\n","from huggingface_hub import notebook_login\n","from IPython.display import display\n","from IPython.display import Image as displayImage\n","from PIL import Image"],"metadata":{"id":"FLzJmKeachj1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Device"],"metadata":{"id":"5-ZWDdbzvvAc"}},{"cell_type":"code","source":["# Select cuda(use gpu) or cpu\n","DEVICE = \"cuda\""],"metadata":{"id":"7j_DIxe5vwe4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Login hugging face"],"metadata":{"id":"NNfC4fmQdcvB"}},{"cell_type":"code","source":["notebook_login()"],"metadata":{"id":"NVeu5ECCdDRn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Pipeline"],"metadata":{"id":"TEdi5q0Ld2g-"}},{"cell_type":"code","source":["def _create_pipeline(device: str) -> StableDiffusionImg2ImgPipeline:\n","    params = dict()\n","    if device == \"cuda\":\n","        params[\"revision\"] = \"fp16\"\n","        params[\"torch_dtype\"] = torch.float16\n","\n","    pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n","        \"CompVis/stable-diffusion-v1-4\",\n","        use_auth_token=True,\n","        **params,\n","    )\n","    pipe.to(device)\n","\n","    return pipe\n","\n","\n","PIPE = _create_pipeline(DEVICE)"],"metadata":{"id":"gAAbuu1Hdgdc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Create and show image"],"metadata":{"id":"61n_KrjifdcX"}},{"cell_type":"code","source":["def preprocess_image(image: Image.Image, size: tuple[int, int]) -> torch.Tensor:\n","    if image.mode in (\"RGBA\", \"LA\") or (image.mode == \"P\" and \"transparency\" in image.info):\n","        alpha = image.convert(\"RGBA\").split()[-1]\n","        bg = Image.new(\"RGBA\", image.size, (255, 255, 255, 255))\n","        bg.paste(image, mask=alpha)\n","        image = image.convert(\"RGB\")\n","\n","    # resize to integer multiple of 32\n","    w, h = map(lambda x: x - x % 32, size)  \n","    image_pil = image.resize((w, h), resample=Image.LANCZOS)\n","\n","    # convert image values to the range of -1 ~ 1\n","    image_np = np.array(image_pil).astype(np.float32) / 255.0\n","    image_np = 2.0 * image_np - 1.0\n","    image_np = image_np[np.newaxis].transpose(0, 3, 1, 2)\n","\n","    image_torch = torch.from_numpy(image_np)\n","\n","    return image_torch"],"metadata":{"id":"QG0Y6TR6gjks"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def _infer(\n","    pipe: StableDiffusionImg2ImgPipeline,\n","    prompt: str,  #  The prompt to guide the image generation.\n","    init_image: torch.Tensor,  # tensor representing an image batch, that will be used as the starting point for the process.\n","    strength: float = 0.8,  # Conceptually, indicates how much to transform the reference `init_image`. Must be between 0 and 1.\n","    guidance_scale: float = 7.5,\n","    num_inference_steps: int = 50,  # The number of denoising steps.\n","    seed: int = 42,  # random seed.\n","    device: str = \"cuda\",\n",") -> Image.Image:\n","    generator = torch.Generator(device=device).manual_seed(seed)\n","    print(init_image.shape)\n","    with torch.autocast(device):\n","        images = pipe(\n","            [prompt],\n","            init_image=init_image,\n","            strength=strength,\n","            guidance_scale=guidance_scale,\n","            num_inference_steps=num_inference_steps,\n","            generator=generator,\n","        ).images\n","\n","    return images[0]"],"metadata":{"id":"xJIUJSOz1sty"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def _save_and_show_image(image: Image.Image, filepath: Path) -> None:\n","    print(type(image))\n","    image.save(filepath)\n","    display(displayImage(filepath))"],"metadata":{"id":"SOHlVqn62frZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PROMPT = \"\"\"character concept, portrait, Unreal Engine\"\"\"\n","IMAGE = _infer(\n","    pipe=PIPE,\n","    prompt=PROMPT,\n","    init_image=preprocess_image(Image.open(\"FbQVaVtUIAA41yk.jpg\"), size=(512, 512)),\n","    strength=0.8,\n","    guidance_scale=7.5,\n","    num_inference_steps=50,\n","    seed=42,\n","    device=DEVICE,\n",")\n","_save_and_show_image(IMAGE, filepath=Path(\"test.png\"))"],"metadata":{"id":"bF4EW7oqfc9_"},"execution_count":null,"outputs":[]}]}